"""
Project #277: Knowledge Distillation with Transformers
Category: Deep Learning

Apply knowledge distillation from BERT to a smaller model for text classification on IMDb reviews using Hugging Face. This teaches transformer compression.
"""

# Start your implementation here...
