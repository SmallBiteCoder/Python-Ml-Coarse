"""

s.no: 251
Name: Teacher-Student Knowledge Distillation
category: Deep Learning
project_discription: Implement knowledge distillation from a large CNN to a smaller model for CIFAR-10 using Keras. This teaches model compression techniques.
Project requirements: {'language': 'Python', 'libraries': ['tensorflow'], 'concepts': ['Knowledge distillation', 'Model compression', 'CNN'], 'learn topics from': ['https://keras.io/examples/vision/knowledge_distillation/', 'https://keras.io/api/datasets/cifar10/']}
Time: 90
Difficulty: 75
"""

# Start your implementation here...
